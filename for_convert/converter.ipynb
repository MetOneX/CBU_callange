{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import xml.etree.ElementTree as ET\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "BASE_DIR = Path(\"..\").resolve()\n",
    "SRC_DIR = BASE_DIR / \"for_convert\"\n",
    "DST_DIR = BASE_DIR / \"converted_csv\"\n",
    "DST_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def convert_jsonl_to_csv(filename: str):\n",
    "    jsonl_path = SRC_DIR / filename\n",
    "    csv_path = DST_DIR / (Path(filename).stem + \".csv\")\n",
    "\n",
    "    rows = []\n",
    "    with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            obj = json.loads(line)\n",
    "            rows.append(obj)\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"[JSONL] No rows found in {jsonl_path}\")\n",
    "        return\n",
    "\n",
    "    fieldnames = sorted({k for row in rows for k in row.keys()})\n",
    "\n",
    "    with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"[JSONL] {jsonl_path} -> {csv_path}\")"
   ],
   "id": "6d9852786543018a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def convert_xml_to_csv(filename: str, row_tag: str = \"customer\"):\n",
    "    xml_path = SRC_DIR / filename\n",
    "    csv_path = DST_DIR / (Path(filename).stem + \".csv\")\n",
    "\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    rows = []\n",
    "    for elem in root.findall(row_tag):\n",
    "        row = {}\n",
    "        for child in elem:\n",
    "            row[child.tag] = (child.text or \"\").strip()\n",
    "        rows.append(row)\n",
    "\n",
    "    if not rows:\n",
    "        print(f\"[XML] No <{row_tag}> rows found in {xml_path}\")\n",
    "        return\n",
    "\n",
    "    fieldnames = sorted({k for row in rows for k in row.keys()})\n",
    "\n",
    "    with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    print(f\"[XML] {xml_path} -> {csv_path}\")"
   ],
   "id": "f9f6a4efee00cf8e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def convert_parquet_to_csv(filename: str):\n",
    "    parquet_path = SRC_DIR / filename\n",
    "    csv_path = DST_DIR / (Path(filename).stem + \".csv\")\n",
    "\n",
    "    df = pd.read_parquet(parquet_path)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "\n",
    "    print(f\"[PARQUET] {parquet_path} -> {csv_path}\")"
   ],
   "id": "9e3eed2573d959ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "convert_jsonl_to_csv(\"financial_ratios.jsonl\")\n",
    "convert_xml_to_csv(\"geographic_data.xml\", row_tag=\"customer\")\n",
    "convert_parquet_to_csv(\"credit_history.parquet\")"
   ],
   "id": "de068831c948a02e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
